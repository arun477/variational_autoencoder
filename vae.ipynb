{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from datasets import load_dataset\n",
    "import fastcore.all as fc\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.data import DataLoader, default_collate\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset fashion_mnist (/Users/arun/.cache/huggingface/datasets/fashion_mnist/fashion_mnist/1.0.0/0a671f063342996f19779d38c0ab4abef9c64f757b35af8134b331c294d7ba48)\n",
      "100%|██████████| 2/2 [00:00<00:00, 51.53it/s]\n"
     ]
    }
   ],
   "source": [
    "name = 'fashion_mnist'\n",
    "x,y = 'image','label'\n",
    "dsr = load_dataset(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(b):\n",
    "    b[x] = [TF.to_tensor(ele) for ele in b[x]]\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = dsr.with_transform(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_dict(b):\n",
    "     clt = default_collate(b)\n",
    "     return (clt[x], clt[y])\n",
    "\n",
    "class DataLoaders:\n",
    "     def __init__(self, train_ds, valid_ds, batch_size, collate_fn, **kwargs):\n",
    "          self.train = DataLoader(train_ds, batch_size=batch_size, collate_fn=collate_fn, shuffle=True, **kwargs)\n",
    "          self.valid = DataLoader(valid_ds, batch_size=batch_size*2, collate_fn=collate_fn, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 1024\n",
    "dls = DataLoaders(dst['train'], dst['test'], batch_size=bs, collate_fn=collate_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1024, 1, 28, 28]), torch.Size([1024]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb,yb = next(iter(dls.train))\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xb[0].permute(1, 2, 0));\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(ni, nf, ks=3, s=2, act=nn.ReLU, norm=None, bias=True):\n",
    "    layers = [nn.Conv2d(ni, nf, kernel_size=ks, stride=s, padding=ks//2, bias=bias)]\n",
    "    if norm is not None:\n",
    "        layers.append(norm)\n",
    "    if act:\n",
    "        layers.append(act())\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def _conv_block(ni, nf, ks=3, s=2, act=nn.ReLU, norm=None, bias=True):\n",
    "    return nn.Sequential(\n",
    "        conv(ni, nf, ks=ks, s=1, act=act, bias=bias),\n",
    "        conv(nf, nf, s=s, norm=norm, act=None, bias=bias)\n",
    "    )\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, ni, nf, ks=3, s=2, act=nn.ReLU, norm=None, bias=True):\n",
    "        super().__init__()\n",
    "        self.conv = _conv_block(ni, nf, ks=ks, s=s, act=act, norm=norm, bias=bias)\n",
    "        self.idconv = fc.noop if ni==nf else conv(ni, nf, s=1, ks=1, act=None)\n",
    "        self.pool = nn.noop if s==1 else nn.AvgPool2d(2, ceil_mode=True)\n",
    "        self.act = act()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.act(self.conv(x) + self.idconv(self.pool(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cls = self._cls()\n",
    "    \n",
    "    def _cls(self):\n",
    "        return nn.Sequential(\n",
    "            ResBlock(1, 8),\n",
    "            ResBlock(8, 16),\n",
    "            ResBlock(16, 32),\n",
    "            ResBlock(32, 64),\n",
    "            ResBlock(64, 64),\n",
    "            conv(64, 10, act=False),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.cls(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 10])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Classifier()\n",
    "model(xb).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaiming_init(m):\n",
    "    if isinstance(m, (nn.Conv1d, nn.Conv2d, nn.Conv3d)):\n",
    "        nn.init.kaiming_normal_(m.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, loss: 0.5400\n",
      "epoch:2, loss: 0.3413\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "lr = 0.01\n",
    "max_lr = 0.2\n",
    "model = Classifier()\n",
    "model.apply(kaiming_init)\n",
    "opt = optim.AdamW(model.parameters(), lr=lr)\n",
    "sched = optim.lr_scheduler.OneCycleLR(opt, max_lr=max_lr, total_steps=len(dls.train), epochs=epochs)\n",
    "for epoch in range(epochs):\n",
    "    dl = dls.train\n",
    "    for xb,yb in dl:\n",
    "        pred = model(xb)\n",
    "        loss = F.cross_entropy(pred, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    sched.step()\n",
    "    print(f\"epoch:{epoch+1}, loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
