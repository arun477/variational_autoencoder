{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from datasets import load_dataset\n",
    "import fastcore.all as fc\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.data import DataLoader, default_collate\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset fashion_mnist (/Users/arun/.cache/huggingface/datasets/fashion_mnist/fashion_mnist/1.0.0/0a671f063342996f19779d38c0ab4abef9c64f757b35af8134b331c294d7ba48)\n",
      "100%|██████████| 2/2 [00:00<00:00, 49.94it/s]\n"
     ]
    }
   ],
   "source": [
    "name = 'fashion_mnist'\n",
    "x,y = 'image','label'\n",
    "dsr = load_dataset(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(b):\n",
    "    b[x] = [TF.to_tensor(ele) for ele in b[x]]\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = dsr.with_transform(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_dict(b):\n",
    "     clt = default_collate(b)\n",
    "     return (clt[x], clt[y])\n",
    "\n",
    "class DataLoaders:\n",
    "     def __init__(self, train_ds, valid_ds, batch_size, collate_fn, **kwargs):\n",
    "          self.train = DataLoader(train_ds, batch_size=batch_size, collate_fn=collate_fn, shuffle=True, **kwargs)\n",
    "          self.valid = DataLoader(valid_ds, batch_size=batch_size*2, collate_fn=collate_fn, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 1024\n",
    "dls = DataLoaders(dst['train'], dst['test'], batch_size=bs, collate_fn=collate_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1024, 1, 28, 28]), torch.Size([1024]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb,yb = next(iter(dls.train))\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xb[0].permute(1, 2, 0));\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(ni, nf, ks=3, s=2, act=nn.ReLU, norm=None, bias=True):\n",
    "    layers = [nn.Conv2d(ni, nf, kernel_size=ks, stride=s, padding=ks//2, bias=bias)]\n",
    "    if norm is not None:\n",
    "        layers.append(norm)\n",
    "    if act:\n",
    "        layers.append(act())\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def _conv_block(ni, nf, ks=3, s=2, act=nn.ReLU, norm=None, bias=True):\n",
    "    return nn.Sequential(\n",
    "        conv(ni, nf, ks=ks, s=1, act=act, bias=bias),\n",
    "        conv(nf, nf, s=s, norm=norm, act=None, bias=bias)\n",
    "    )\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, ni, nf, ks=3, s=2, act=nn.ReLU, norm=None, bias=True):\n",
    "        super().__init__()\n",
    "        self.conv = _conv_block(ni, nf, ks=ks, s=s, act=act, norm=norm, bias=bias)\n",
    "        self.idconv = fc.noop if ni==nf else conv(ni, nf, s=1, ks=1, act=None)\n",
    "        self.pool = nn.noop if s==1 else nn.AvgPool2d(2, ceil_mode=True)\n",
    "        self.act = act()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.act(self.conv(x) + self.idconv(self.pool(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cls = self._cls()\n",
    "    \n",
    "    def _cls(self):\n",
    "        return nn.Sequential(\n",
    "        ResBlock(1, 8, norm=nn.LayerNorm([8, 14, 14])),\n",
    "        ResBlock(8, 16, norm=nn.LayerNorm([16, 7, 7])),\n",
    "        ResBlock(16, 32, norm=nn.LayerNorm([32, 4, 4])),\n",
    "        ResBlock(32, 64, norm=nn.LayerNorm([64, 2, 2])),\n",
    "        ResBlock(64, 64,  norm=nn.LayerNorm([64, 1, 1])),\n",
    "        conv(64, 10, act=False),\n",
    "        nn.Flatten(),\n",
    "    )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.cls(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 10])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Classifier()\n",
    "model(xb).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaiming_init(m):\n",
    "    if isinstance(m, (nn.Conv1d, nn.Conv2d, nn.Conv3d)):\n",
    "        nn.init.kaiming_normal_(m.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "lr = 0.01\n",
    "max_lr = 0.2\n",
    "model = Classifier()\n",
    "model.apply(kaiming_init)\n",
    "opt = optim.AdamW(model.parameters(), lr=lr)\n",
    "sched = optim.lr_scheduler.OneCycleLR(opt, max_lr=max_lr, total_steps=len(dls.train), epochs=epochs)\n",
    "for epoch in range(epochs):\n",
    "    for train in (True, False):\n",
    "        dl = dls.train if train else dls.valid\n",
    "        accuracy = 0\n",
    "        for xb,yb in dl:\n",
    "            pred = model(xb)\n",
    "            loss = F.cross_entropy(pred, yb)\n",
    "            if train:\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "                opt.zero_grad()\n",
    "            with torch.no_grad():\n",
    "                accuracy += (pred.argmax(dim=1) == yb).float().mean()\n",
    "        accuracy /= len(dl)\n",
    "        if train:\n",
    "            sched.step()\n",
    "        print(f\"train: {'train' if train else 'eval'}, epoch:{epoch+1}, loss: {loss.item():.4f}, accuracy:{accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reshape(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x.view(self.dim)\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = self._encoder()\n",
    "        self.decoder = self._decoder()\n",
    "    \n",
    "    def _encoder(self):\n",
    "        return nn.Sequential(\n",
    "            ResBlock(1, 8),\n",
    "            ResBlock(8, 16),\n",
    "            ResBlock(16, 32),\n",
    "            ResBlock(32, 64),\n",
    "            ResBlock(64, 64),\n",
    "            conv(64, 10, act=False),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "    \n",
    "    def _decoder(self):\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(10, 64),\n",
    "            Reshape((-1, 64, 1, 1)),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=2),\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=3),\n",
    "            nn.ConvTranspose2d(16, 8, kernel_size=8),\n",
    "            nn.ConvTranspose2d(8, 1, kernel_size=14),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 1, 24, 24])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoEncoder()\n",
    "output = model(xb).detach().cpu()\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "lr = 0.01\n",
    "max_lr = 0.2\n",
    "model = Classifier()\n",
    "model.apply(kaiming_init)\n",
    "opt = optim.AdamW(model.parameters(), lr=lr)\n",
    "sched = optim.lr_scheduler.OneCycleLR(opt, max_lr=max_lr, total_steps=len(dls.train), epochs=epochs)\n",
    "for epoch in range(epochs):\n",
    "    for train in (True, False):\n",
    "        dl = dls.train if train else dls.valid\n",
    "        accuracy = 0\n",
    "        for xb,yb in dl:\n",
    "            pred = model(xb)\n",
    "            loss = F.cross_entropy(pred, yb)\n",
    "            if train:\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "                opt.zero_grad()\n",
    "            with torch.no_grad():\n",
    "                accuracy += (pred.argmax(dim=1) == yb).float().mean()\n",
    "        accuracy /= len(dl)\n",
    "        if train:\n",
    "            sched.step()\n",
    "        print(f\"train: {'train' if train else 'eval'}, epoch:{epoch+1}, loss: {loss.item():.4f}, accuracy:{accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
